export const personalInfo = {
  name: "Sathish Kumar V",
  title: "AI Architect | Building Production LLM Systems & RAG Architectures | Azure AI Foundry | AWS Bedrock | Python | Data Engineer",
  description: "Specialized in building production-grade AI systems and intelligent automation solutions. Expert in LLMs, RAG architectures, and OCR pipelines that deliver measurable business impact.",
  email: "sathishkumar05@gmail.com",
  phone: "+91 8056770991",
  website: "https://vpsathish05.github.io/sathish-portfolio/",
  linkedin: "https://www.linkedin.com/in/sathish-kumar-310976153/",
  github: "https://github.com/vpsathish05",
  reddit: "https://www.reddit.com/user/vpsr05/",
  medium: "https://medium.com/@vpsathish05",
  avatar: "/sathish-teams-img.png",
  location: "Chennai, India"
};

export const aboutMe = {
  summary: "AI Engineer with 5+ years of experience architecting and deploying production-grade intelligent systems. Currently focused on building scalable AI solutions leveraging Large Language Models, Retrieval Augmented Generation, and computer vision technologies to solve complex enterprise challenges.",
  details: "Specialized in developing end-to-end AI solutions across the full development lifecycle-from document understanding and OCR pipelines to LLM integration and production deployment. Deep expertise in cloud AI platforms including Azure AI Foundry and AWS Bedrock for building enterprise-grade intelligent applications. Strong foundation in software engineering principles, modern web technologies, and data engineering, enabling delivery of robust AI systems that integrate seamlessly with existing business infrastructure and drive measurable outcomes."
};;

export const education = [
  { degree: "MCA", institution: "University of Madras IDE", year: "2017-2020", grade: "70%" },
  { degree: "BCA", institution: "Jairam Arts and Science College", year: "2014-2017", grade: "66%" },
  { degree: "HSS", institution: "Velasamy Chettiar HSS", year: "2014", grade: "65%" },
  { degree: "SSLC", institution: "Velasamy Chettiar HSS", year: "2012", grade: "66%" }
];

export const skills = {
  programming: [
    { name: "Python", color: "#3776AB" },
    { name: "TypeScript", color: "#3178C6" },
    { name: "JavaScript", color: "#F7DF1E" },
    { name: "C#", color: "#239120" }
  ],
  ai: [
    { name: "LangChain", color: "#1C3C3C" },
    { name: "OpenAI API", color: "#412991" },
    { name: "RAG", color: "#FF6B6B" },
    { name: "Azure AI Foundry", color: "#0089D6" },
    { name: "AWS Bedrock", color: "#FF9900" },
    { name: "PaddleOCR", color: "#0052CC" },
    { name: "Vector Databases", color: "#00ADEF" },
    { name: "Databricks", color: "#FF3621" }
  ],
  fullstack: [
    { name: "Next.js", color: "#000000" },
    { name: "React", color: "#61DAFB" },
    { name: "Angular", color: "#DD0031" },
    { name: "Node.js", color: "#339933" },
    { name: "NestJS", color: "#E0234E" },
    { name: "FastAPI", color: "#009688" },
    { name: ".NET Core", color: "#512BD4" }
  ],
  data: [
    { name: "dbt", color: "#FF694B" },
    { name: "Amazon Redshift", color: "#8C4FFF" },
    { name: "PostgreSQL", color: "#336791" },
    { name: "Azure Data Factory", color: "#0089D6" },
    { name: "SQL Server", color: "#CC2927" }
  ]
};

export const experiences = [
  {
    title: "Solutions Consultant",
    company: "JMAN Group, Chennai",
    date: "Oct 2025 – Present",
    description: "Leading AI solution architecture and implementation for enterprise clients. Specializing in Agentic AI systems, Azure AI Foundry, and AWS AI services to deliver intelligent automation solutions. Building production-grade RAG architectures and document intelligence platforms using Amazon Textract and Kendra."
  },
  {
    title: "Solution Enabler",
    company: "JMAN Group, Chennai",
    date: "Apr 2024 – Nov 2025",
    description: "Architected and deployed GenAI-based products including AI chatbots and document intelligence systems. Led development of contract extraction platform reducing processing time from 260 hours to 26 minutes. Implemented RAG architectures with vector databases, Azure AI Foundry, and Amazon Textract. Built data platforms using dbt, Azure Data Factory, and Redshift while developing full-stack applications with Next.js, React, and NestJS."
  },
  {
    title: "Senior Software Engineer",
    company: "JMAN Group, Chennai",
    date: "Apr 2023 – Apr 2024",
    description: "Enhanced data pipelines for increased scalability and performance using dbt, Azure Data Factory, and Matillion ETL. Optimized ETL processes and developed data models in Amazon Redshift and SQL Server. Built full-stack applications using Angular, React, Node.js, and TypeScript while implementing data quality checks to ensure data integrity."
  },
  {
    title: "Software Engineer",
    company: "JMAN Group, Chennai",
    date: "Feb 2022 – Apr 2023",
    description: "Developed RESTful APIs and optimized front-end components using Node.js, NestJS, and React. Implemented ETL pipelines with Azure Data Factory and worked on containerized deployments using Docker. Built responsive user interfaces with Angular and Next.js while optimizing database queries for improved performance."
  },
  {
    title: "Full Stack Developer",
    company: "Elroi Software Solutions, Chennai",
    date: "Sep 2021 – Feb 2022",
    description: "Developed enterprise applications using C# and .NET Framework. Implemented database solutions using SQL Server and built web applications with ASP.NET MVC and Entity Framework. Contributed to various programming projects focusing on backend logic and database management."
  },
  {
    title: "Full-Stack Developer",
    company: "Qserve UAE, Chennai",
    date: "Aug 2020 – Nov 2020",
    description: "Developed a Retail Management System covering core functionalities like order processing, sales tracking, accounting, and inventory management. Utilized .NET Core, SQL Server, ASP.NET MVC, and LINQ for building a robust and scalable application with Azure server integration."
  },
  {
    title: "Software Developer",
    company: "RmKV Computask Pvt. Ltd., Chennai",
    date: "Jul 2017 – Aug 2018",
    description: "Maintained and enhanced long-term enterprise applications supporting day-to-day operational requirements for RmKV Group of Companies. Managed separate databases for multiple company locations and customized modules for Sales, Accounts, Inventory, Customers, Human Resources, and Systems. Worked with SQL Server, C#, Angular, and .NET Framework."
  }
];

export const projects = [
  {
    id: "contract-extraction",
    title: "Contract Intelligence Platform",
    company: "Enterprise Client",
    role: "Technical Lead",
    techStack: [
      { name: "Python", color: "#3776AB" },
      { name: "PaddleOCR", color: "#0052CC" },
      { name: "GPT-4", color: "#412991" },
      { name: "LangChain", color: "#1C3C3C" },
      { name: "Microsoft TATR", color: "#0089D6" },
      { name: "PostgreSQL", color: "#336791" },
      { name: "FastAPI", color: "#009688" }
    ],
    description: "Built an AI-powered contract extraction system that reduced 260 hours of manual processing to 26 minutes. The platform combines OCR, layout analysis, and LLM-powered semantic extraction to process thousands of contracts with 85-90% straight-through processing and <1% error rates.",
    details: [
      "Engineered a multi-stage pipeline handling scanned PDFs, complex tables, and cross-page dependencies using PaddleOCR PP-OCRv5 and Microsoft Table Transformer.",
      "Implemented semantic chunking and context preservation strategies to process 200-page contracts within LLM context windows while maintaining cross-reference accuracy.",
      "Designed validation and human-in-the-loop systems with confidence scoring, business rules validation, and active learning to ensure production-grade accuracy."
    ],
    demoUrl: "https://medium.com/@vpsathish05/contract-intelligence-at-scale-how-ocr-llm-turned-260-hours-into-26-minutes-00dc6aab26a0",
    githubUrl: null
  },
  {
    id: "ai-chatbot",
    title: "AI Research Chatbot",
    company: "Healthcare Client",
    role: "Project Manager + Technical Lead",
    techStack: [
      { name: "Next.js", color: "#000000" },
      { name: "Chroma DB", color: "#00ADEF" },
      { name: "Postgres Vector DB", color: "#336791" },
      { name: "LangChain", color: "#1C3C3C" },
      { name: "OpenAI API", color: "#412991" },
      { name: "PubMed API", color: "#326295" },
      { name: "Google Scholar API", color: "#4285F4" },
      { name: "RAG", color: "#FF6B6B" }
    ],
    description: "Designed and developed an advanced AI-powered chatbot using Next.js integrated with vector embeddings and sophisticated indexing for enhanced natural language processing. The system leverages RAG (Retrieval Augmented Generation) architecture to provide accurate and contextual responses.",
    details: [
      "Implemented vector database solutions using Chroma DB and Postgres with pgvector extension for efficient similarity search and document retrieval.",
      "Integrated multiple academic APIs including PubMed and Google Scholar for comprehensive research data access.",
      "Led the technical architecture decisions and managed the project timeline while ensuring high-quality deliverables and maintaining clear communication with stakeholders."
    ],
    demoUrl: null,
    githubUrl: null
  },
  {
    id: "data-platform",
    title: "Enterprise Data Platform",
    company: "Financial Services Client",
    role: "Project Manager + Data Engineer",
    techStack: [
      { name: "dbt cloud", color: "#FF694B" },
      { name: "Redshift", color: "#8C4FFF" },
      { name: "Atlassian", color: "#0052CC" }
    ],
    description: "Built and managed a comprehensive data platform utilizing modern data warehouse architecture to centralize and analyze corporate growth data. Implemented sophisticated data models using dbt cloud for efficient transformation and analysis.",
    details: [
      "Designed and optimized complex SQL queries and data models in Redshift, significantly improving query performance and data accessibility.",
      "Integrated Atlassian tools for project management and documentation.",
      "Led the data engineering team, established best practices for data modeling, and ensured successful delivery of data solutions while maintaining high data quality standards."
    ],
    demoUrl: null,
    githubUrl: null
  }
];
